{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_loader\n",
    "\n",
    "A library to load the MNIST image data.  For details of the data structures that are returned, see the doc strings for `load_data` and `load_data_wrapper`.  \n",
    "\n",
    "In practice, `load_data_wrapper` is the function usually called by our neural network code.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST-loader\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Standard library\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Load_data()`\n",
    "\n",
    "Return the MNIST data as a tuple containing the training data, the validation data, and the test data.\n",
    "\n",
    "The ``training_data`` is returned as a tuple with two entries.\n",
    "\n",
    "The first entry contains the actual training images.  This is a numpy ndarray with 50,000 entries.  Each entry is, in turn, a numpy ndarray with 784 values, representing the 28 * 28 = 784 pixels in a single MNIST image.\n",
    "\n",
    "The second entry in the ``training_data`` tuple is a numpy ndarray containing 50,000 entries.  Those entries are just the digit values (0...9) for the corresponding images contained in the first entry of the tuple.\n",
    "\n",
    "The ``validation_data`` and ``test_data`` are similar, except each contains only 10,000 images. \n",
    "\n",
    "This is a nice data format, but for use in neural networks it's helpful to modify the format of the ``training_data`` a little. That's done in the wrapper function ``load_data_wrapper()``, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `load_data_wrapper()`\n",
    "\n",
    "Return a tuple containing ``(training_data, validation_data, test_data)``. Based on ``load_data``, but the format is more convenient for use in our implementation of neural networks. \n",
    "\n",
    "In particular, ``training_data`` is a list containing 50,000 2-tuples ``(x, y)``.  \n",
    "\n",
    "``x`` is a 784-dimensional numpy.ndarray containing the input image.  \n",
    "\n",
    "``y`` is a 10-dimensional numpy.ndarray representing the unit vector corresponding to the correct digit for ``x``. \n",
    "\n",
    "``validation_data`` and ``test_data`` are lists containing 10,000 2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional numpy.ndarry containing the input image, and ``y`` is the corresponding classification, i.e., the digit values (integers)corresponding to ``x``.\n",
    "\n",
    "Obviously, this means we're using slightly different formats for the training data and the validation / test data.  These formats turn out to be the most convenient for use in our neural network code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MNIST-loader test\")\n",
    "def load_data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = zip(validation_inputs, va_d[1])\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = zip(test_inputs, te_d[1])\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `vectorized_result(j)`\n",
    "\n",
    "Return a 10-dimensional unit vector with a 1.0 in the jth position and zeroes elsewhere.  This is used to convert a digit (0...9) into a corresponding desired output from the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
